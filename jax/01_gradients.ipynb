{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = 8, 6\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a derivative of a function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A measure of how the function changes when changes are made to its _independent_ variable(s).**\n",
    "\n",
    "**When this independent variable is time, this is also called the _rate of change_ of the function.**\n",
    "\n",
    "## Example: $$ f(x) = 2x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 100, 100)\n",
    "yy = 2 * xx\n",
    "plt.plot(xx, yy)\n",
    "plt.vlines(70, 0, yy[70], linestyles=\"dashed\", colors=\"g\")\n",
    "plt.vlines(85, 0, yy[85], linestyles=\"dashed\", colors=\"g\")\n",
    "plt.hlines(yy[70], 0, 70, linestyles=\"dashed\", colors=\"g\")\n",
    "plt.hlines(yy[85], 0, 85, linestyles=\"dashed\", colors=\"g\")\n",
    "plt.xticks([70, 85], [r\"$a$\", r\"$a + \\Delta a$\"], fontsize=12, color=\"k\")\n",
    "plt.yticks([yy[70], yy[85]], [r\"$f(a)$\", r\"$f(a + \\Delta a)$\"], fontsize=12, color=\"k\")\n",
    "plt.xlabel(r'$x$', fontsize=16, color=\"k\")\n",
    "_ = plt.ylabel(r'$f(x)$', fontsize=16, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of $f$\n",
    "### also called _slope_ or _gradient_ of $f$\n",
    "\n",
    "### $$ f'(x) = \\frac{df}{dx} = \\lim_{x \\to 0}\\frac{f(x + \\Delta x) - f(x)}{\\Delta x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Derivative of the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "f = sigmoid(x)\n",
    "\n",
    "plt.plot(x, f)\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize=20, color=\"k\")\n",
    "_ = plt.ylabel(r'$\\frac{1}{1 + e^{-x}}$', fontsize=20, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain rule of differentiation:\n",
    "# $$ \\frac{d}{dx}[f(g(x))] = \\frac{df}{dg}\\frac{dg}{dx}$$\n",
    "\n",
    "### Suppose $$g(x) = 1 + e^{-x}$$\n",
    "### $$\\therefore f(x) = \\frac{1}{g}$$\n",
    "\n",
    "### Thus by chain rule:\n",
    "### $$f'(x) = \\frac{df}{dg} g'(x)$$\n",
    "### $$\\therefore f'(x) = -\\frac{df}{dg}e^{-x}$$\n",
    "### $$\\therefore f'(x) = -\\frac{d}{dg}\\frac{1}{g}e^{-x}$$\n",
    "### $$\\therefore f'(x) = \\frac{1}{g^{2}}e^{-x}$$\n",
    "### $$\\therefore f'(x) = \\frac{e^{-x}}{(1 + e^{-x})^{2}}$$\n",
    "### Adding and subtracting unity from the numerator:\n",
    "### $$f'(x) = \\frac{1 + e^{-x} - 1}{(1 + e^{-x})^{2}}$$\n",
    "### Splitting the fraction\n",
    "### $$f'(x) = \\frac{1 + e^{-x}}{(1 + e^{-x})^{2}} - \\frac{1}{(1 + e^{-x})^{2}}$$\n",
    "### Simplifying...\n",
    "### $$f'(x) = \\frac{1}{1 + e^{-x}} - \\frac{1}{(1 + e^{-x})^{2}}$$\n",
    "### $$f'(x) = \\frac{1}{1 + e^{-x}}\\bigg(1 - \\frac{1}{1 + e^{-x}}\\bigg)$$\n",
    "### Substituting for sigmoid function:\n",
    "### $$f'(x) = g(1 - g)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "f = sigmoid(x)\n",
    "df_dx = f * (1 - f)\n",
    "\n",
    "plt.plot(x, f, label=r'$f(x)$')\n",
    "plt.plot(x, df_dx, label=r'$\\frac{df}{dx}$')\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize=20, color=\"k\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "xx = np.linspace(-6, 6, 1000)\n",
    "d_x = jax.grad(sigmoid)\n",
    "df_dx = jax.vmap(d_x)(xx)\n",
    "\n",
    "\n",
    "plt.plot(xx, sigmoid(xx), label=r'$f(x)$')\n",
    "plt.plot(xx, df_dx, label=r'$\\frac{df}{dx}$')\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize=20, color=\"k\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Plot the Hyperbolic Tangent function and its derivative\n",
    "## $$tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Partial Derivatives\n",
    "### A partial derivative of a multivariate function $f(x_{1}, x_{2}, ...)$, w.r.t. to one of it's dependent variables, say $x_{1}$ is derivative of $f$ w.r.t. $x_{1}$ assuming $x_{k} \\forall k \\neq 1$ to be constant.\n",
    "\n",
    "### How many such derivatives?\n",
    "### Thus, a partial derivative is always a vector.\n",
    "\n",
    "### Given $f(x, y) = x^{2}y + y$\n",
    "### Partial derivative of $f$ w.r.t $x$ is $\\frac{\\partial{f}}{\\partial{x}}$\n",
    "### Partial derivative of $f$ overall is $\\nabla{f}$\n",
    "### $$\\nabla{f} = \\begin{bmatrix}\n",
    "\\frac{\\partial{f}}{\\partial{x}}\\\\\n",
    "\\frac{\\partial{f}}{\\partial{y}}\n",
    "\\end{bmatrix}$$\n",
    "### By derivation,\n",
    "### $$\\frac{\\partial{f}}{\\partial{x}} = 2xy$$\n",
    "### $$\\frac{\\partial{f}}{\\partial{y}} = x^{2} + 1$$\n",
    "### Thus\n",
    "### $$\\nabla{f} = \\begin{bmatrix}\n",
    "2xy\\\\\n",
    "x^{2} + 1\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.g the Mexican Hat / Ricker Wavelet :\n",
    "## $$\n",
    "f(x, y) = \\frac{1}{\\pi\\sigma^4}\\Big(1 - \\frac{1}{2}\\Big(\\frac{x^2 + y^2}{\\sigma^2}\\Big)\\Big)e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def mexican_hat(x, y, sigma=0.25):\n",
    "    exp = -0.5 * (x ** 2 + y ** 2) / (sigma ** 2)\n",
    "    return 1 / (np.pi * sigma ** 4) * (1 + exp) * np.exp(exp)\n",
    "\n",
    "xx = np.linspace(-1, 1, 100)\n",
    "yy = np.linspace(-1, 1, 100)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "Z = mexican_hat(X, Y)\n",
    "\n",
    "# Plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap=plt.cm.coolwarm)\n",
    "ax.set_zticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel(r'$x$', fontsize=16, color=\"k\")\n",
    "ax.set_ylabel(r'$y$', fontsize=16, color=\"k\")\n",
    "ax.set_zlabel(r'$f(x, y)$', fontsize=16, color=\"k\")\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_gradx = jax.vmap(jax.grad(mexican_hat, 0))(xx, yy)\n",
    "mh_grady = jax.vmap(jax.grad(mexican_hat, 1))(xx, yy)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "ax[0].plot(xx, mh_gradx)\n",
    "ax[1].plot(yy, mh_grady)\n",
    "ax[0].set_xlabel('$x$')\n",
    "ax[1].set_xlabel('$y$')\n",
    "ax[0].set_title(r'$\\frac{\\partial f(x, y)}{\\partial x}$', fontsize='xx-large')\n",
    "_ = ax[1].set_title(r'$\\frac{\\partial f(x, y)}{\\partial y}$', fontsize='xx-large')\n",
    "# [k.set_yticklabels([]) for k in ax.ravel()]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
